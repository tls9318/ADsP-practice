# 회귀분석 실습
# MASS패키지의 Cars93 데이터를 활용
# 종속변수 : price
# 독립변수 : Engine-Size, RPM, Weight

library(MASS)
head(Cars93)
attach(Cars93)
lm(Price ~ EngineSize + RPM + Weight, data = Cars93)
summary(lm(Price ~ EngineSize + RPM + Weight, data = Cars93))

# 해석
# F-통계량 = 37.98, 유의확률(p-value) = 6.746e-16
# 유의수준 5% 하에서 회귀모형이 통계적으로 유의함


# 로지스틱 회귀분석
library(boot)
data(nodal)
a <- c(2, 4, 6, 7)
data <- nodal[,a]
glmModel <- glm(r~., data = data, family = "binomial")
summary(glmModel)

# 해석
# 로지스틱 회귀분석 결과 age, grade는 유의수준 5%하에서 유의하지 않음
# 이를 제외한 3개 변수를 활용해 모델 개발
# 나머지 3개 변수는 5%하에서 유의하게 나타나 선형식이 가능
# 선형식 : p(r=1)=1 / (1 + e-(-3.05 + 1.65stage + 1.91xray + 1.64acid))]

# 최적회귀방정식

# 1. 데이터프레임 생성
x1 <- c(7, 1, 11, 11, 7, 11, 3, 1, 2, 21, 1, 11, 10)
x2 <- c(26, 29, 56, 31, 52, 55, 71, 31, 54, 47, 40, 66, 68)
x3 <- c(6, 15, 8, 8, 6, 9, 17, 22, 18, 4, 23, 9, 8)
x4 <- c(60, 52, 20, 47, 33, 22, 6, 44, 22, 26, 34, 12, 12)
y <- c(78.5, 74.3, 104.3, 87.6, 95.9, 109.2, 102.7, 72.5, 93.1, 115.9, 83.8, 113.3, 109.4)
df <- data.frame(x1, x2, x3, x4, y)
head(df)

# 2. 회귀모형 생성
a <- lm(y ~ x1 + x2 + x3 + x4, data = df)
summary(a)

# 해석
# F- 통계량 = 111.5
# 유의확률 4.756e-07
# 통계적으로 유의함
# t-통계량의 유의확률이 0.05보다 작은 변수가 존재하지 않아 모형 활용 불가
# 유의확률이 가장 높은 x3을 제외하고 다시 회귀모형 생성

# 3. x3 제거후 다시 회귀모형b 생성

b <- lm(y ~ x1 + x2 + x4, data =df)
summary(b)

# 해석
# x1을 제외한 두개의 변수는 0.05보다 높게 나타남
# 유의확률이 가장 높은 x4변수를 제외 후 다시 생성

# 4. 유의확률이 가장 높은 x4를 제거 후 회귀모형(c) 생성
c <- lm(y ~ x1 + x2, data = df)
summary(c)

# 해석
# 다변량 회귀분석으로 선정된 x1 ,x2 변수의 유의확률이 모두 통계적으로 유의
# 수정된 결정계수는 0.9744
# = 다변량 회귀식이 전체 데이터의 97.44%를 설명하는 것을 알 수 있음
# 후진 제거법을통해 얻게된 회귀식
# y = 52.57735 + 1.46831x1 + 0.66225x2

#-----------------------------------
# 전진선택법
step(lm(y ~ 1, data = df), scope = list(lower = ~1, upper = ~x1 + x2 + x3 + x4), direction = "forward")

# 해석
# 가장 먼저 선택된 변수의 aic = 58.852로 가장 낮은 x4
# 최종 회귀식
# y = 71.6483 - 0.2365x4 + 1.519x1 + 0.4164x2
